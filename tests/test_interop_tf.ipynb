{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 12:20:50.344084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-10 12:20:50.362573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-10 12:20:50.367423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-10 12:20:50.379805: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-10 12:20:51.081445: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../build/python')\n",
    "\n",
    "import mitsuba as mi\n",
    "import drjit as dr\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../drjit')\n",
    "\n",
    "from interop import wrap, to_drjit, from_drjit, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tf.Tensor([1. 2. 3. 4.], shape=(4,), dtype=float32)\n",
      "y: tf.Tensor([ 1.  4.  9. 16.], shape=(4,), dtype=float32)\n",
      "Gradient: tf.Tensor([2. 4. 6. 8.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test for a single tensor input\n",
    "\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(input):\n",
    "    return dr.power(input, 2)\n",
    "\n",
    "x = tf.constant([1,2,3,4], tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = dr_func(x)\n",
    "grad = tape.gradient(y, x)\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"Gradient:\", grad)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: tf.Tensor([ 3. 14. 39. 84.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([2. 4. 6. 8.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([ 3. 12. 27. 48.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test with a list of tensors\n",
    "\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(inputs):\n",
    "    result = 0\n",
    "    for i, input in enumerate(inputs):\n",
    "        result += dr.power(input, i+1)\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x3 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "vars = [x1, x2, x3]\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(vars)\n",
    "    result = dr_func(vars)\n",
    "grad = tape.gradient(result, vars)\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: tf.Tensor([  4.  30. 120. 340.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "[<tf.Tensor: shape=(4,), dtype=float32, numpy=array([2., 4., 6., 8.], dtype=float32)>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 3., 12., 27., 48.], dtype=float32)>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([  4.,  32., 108., 256.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Test with a nested list of tensors\n",
    "# Test with a list of tensors\n",
    "\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(inputs):\n",
    "    inputs = sum(inputs, [])\n",
    "    result = 0\n",
    "    for i, input in enumerate(inputs):\n",
    "        result += dr.power(input, i+1)\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x3 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x4 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "vars = [[x1, x2], [x3, x4]]\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(vars)\n",
    "    result = dr_func(vars)\n",
    "grad = tape.gradient(result, [x1, [x2, x3, x4]])\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: tf.Tensor([ 2. 10. 30. 68.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([ 3. 12. 27. 48.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple arguments\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(x1, x2):\n",
    "    return dr.power(x1, 1) + dr.power(x2, 3)\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2])\n",
    "    result = dr_func(x1, x2)\n",
    "grad = tape.gradient(result, [x1, x2])\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 4.,  6.,  8., 10.], dtype=float32)>, None]\n"
     ]
    }
   ],
   "source": [
    "# Test with keyword argument\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(*args, **kwargs):\n",
    "    result = 0\n",
    "    for i, x in enumerate(args[0]):\n",
    "        result += dr.power(x, i+1)\n",
    "\n",
    "    for i, x in enumerate(kwargs.values()):\n",
    "        result += 4*x\n",
    "\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([2, 3, 4, 5], dtype=tf.float32)\n",
    "x3 = tf.constant([3, 4, 4, 5], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2, x3])\n",
    "    result = dr_func([x1, x2], x3=x3)\n",
    "grad = tape.gradient(result, [x1, x2, x3])\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([320. 332. 336. 348.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([4. 4. 4. 4.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test with dict argument\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(*args, **kwargs):\n",
    "    result = 0\n",
    "    for i, x in enumerate(args[0]):\n",
    "        result += dr.power(x, i+1)\n",
    "\n",
    "    for i, x in enumerate(args[1].values()):\n",
    "        result += 4*(i+1)*x\n",
    "\n",
    "    return result\n",
    "\n",
    "def tf_func(*args, **kwargs):\n",
    "    result = 0\n",
    "    for i, x in enumerate(args[0]):\n",
    "        result += tf.pow(x, i+1)\n",
    "\n",
    "    for i, x in enumerate(args[1].values()):\n",
    "        result += 4*(i+1)*x\n",
    "\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([2, 3, 4, 5], dtype=tf.float32)\n",
    "x3 = tf.constant([3, 4, 4, 5], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2, x3])\n",
    "    result = dr_func(x1, {'x2' : x2, 'x3': x3})\n",
    "grad = tape.gradient(result, [x2])\n",
    "print(result)\n",
    "for g in grad:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.autodiff import ForwardAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "Result: tf.Tensor([2. 4. 6. 8.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test with a non differentiable input\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(x1, x2):\n",
    "    return dr.power(x1, 1) + dr.power(x2, 1)\n",
    "\n",
    "def tf_func(x1, x2):\n",
    "    return tf.pow(x1, 1) + tf.cast(tf.pow(x2, 1), x1.dtype)\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.int32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2])\n",
    "    result = dr_func(x1, x2)\n",
    "grad = tape.gradient(result, [x1, x2])\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.constant([1,2,3,4], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drjit as dr\n",
    "from drjit.cuda.ad import Float\n",
    "from drjit.cuda.ad import Int32\n",
    "\n",
    "t = Int32\n",
    "is_diff = False\n",
    "\n",
    "@wrap('drjit', 'torch')\n",
    "def test_fn(x):\n",
    "    return x * 2\n",
    "\n",
    "x = dr.arange(t, 3)\n",
    "dr.enable_grad(x)\n",
    "y = test_fn(x)\n",
    "assert dr.all(y == [0, 2, 4])\n",
    "\n",
    "\n",
    "if is_diff:\n",
    "    y.grad = [10, 20, 30]\n",
    "    dr.backward_to(x)\n",
    "    assert dr.all(x.grad == [20, 40, 60])\n",
    "else:\n",
    "    assert not dr.grad_enabled(y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interop import from_drjit, to_drjit\n",
    "\n",
    "t = dr.llvm.ad.Float\n",
    "x = dr.arange(t, 3)\n",
    "z, _ = from_drjit(x, 'tf', True)\n",
    "y = z*2\n",
    "z_ = to_drjit(y, 'tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "drjit.custom(<interop.WrapADOp>): error while performing a custom differentiable operation. (see above).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: drjit.CustomOp.add_output(): error encountered while processing an argument of type 'drjit.cuda.ad.Float': CustomOpBase::add_index(): can't mix several backends!",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: drjit.CustomOp.add_output(): error encountered while processing an argument of type 'drjit.cuda.ad.TensorXf' (see above).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m t \u001b[38;5;241m=\u001b[39m dr\u001b[38;5;241m.\u001b[39mllvm\u001b[38;5;241m.\u001b[39mad\u001b[38;5;241m.\u001b[39mFloat\n\u001b[1;32m      9\u001b[0m x \u001b[38;5;241m=\u001b[39m dr\u001b[38;5;241m.\u001b[39marange(t, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtest_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/projects/sionna-rt-v-1/mitsuba3/ext/drjit/tests/interop.py:662\u001b[0m, in \u001b[0;36mwrap.<locals>.wrapper.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(func):\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \\\n\u001b[0;32m--> 662\u001b[0m         \u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWrapADOp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: drjit.custom(<interop.WrapADOp>): error while performing a custom differentiable operation. (see above)."
     ]
    }
   ],
   "source": [
    "import drjit as dr\n",
    "\n",
    "\n",
    "@wrap('drjit', 'tf')\n",
    "def test_fn(x):\n",
    "    return x * 2\n",
    "\n",
    "t = dr.llvm.ad.Float\n",
    "x = dr.arange(t, 3)\n",
    "y = test_fn(x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
