{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728635220.949811   90485 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728635220.989228   90485 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728635220.992242   90485 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../build/python')\n",
    "\n",
    "import os # Configure which GPU\n",
    "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
    "    gpu_num = 0 # Use \"\" to use the CPU\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Avoid warnings from TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "\n",
    "import mitsuba as mi\n",
    "import drjit as dr\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../drjit')\n",
    "\n",
    "from interop import wrap, to_drjit, from_drjit, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "4.7683716e-07\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd.forward_ad as fa\n",
    "\n",
    "x_primal = torch.randn(10, 10, dtype=torch.float32)\n",
    "x_tangent = torch.randn(10, 10, dtype=torch.float32)\n",
    "\n",
    "y_primal = torch.randn(10, 10, dtype=torch.float32)\n",
    "y_tangent = torch.zeros_like(y_primal)\n",
    "\n",
    "def fn(x, y):\n",
    "    return x ** 2 + y ** 2\n",
    "\n",
    "with fa.dual_level():\n",
    "    x_dual = fa.make_dual(x_primal, x_tangent)\n",
    "    y_dual = fa.make_dual(y_primal, y_tangent)\n",
    "    z_dual = fn(x_dual, y_dual)\n",
    "    z_tangent = fa.unpack_dual(z_dual).tangent\n",
    "\n",
    "\n",
    "x_primal_tf = tf.constant(x_primal.numpy())\n",
    "x_tangent_tf = tf.constant(x_tangent.numpy())\n",
    "y_primal_tf = tf.constant(y_primal.numpy())\n",
    "y_tangent_tf = tf.constant(y_tangent.numpy())\n",
    "with tf.autodiff.ForwardAccumulator(primals=[x_primal_tf, y_primal_tf],\n",
    "                                    tangents=[x_tangent_tf, y_tangent_tf]) as acc:\n",
    "    z_primal_tf = fn(x_primal_tf, y_primal_tf)\n",
    "    z_tangent_tf = acc.jvp(z_primal_tf)\n",
    "\n",
    "\n",
    "z_tangent.numpy() == z_tangent_tf.numpy()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "print(np.max(np.abs(z_tangent_tf - z_tangent)))\n",
    "print(np.max(np.abs(z_primal_tf - z_dual)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([20., 40., 60.]), 4, 5.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20, 40, 60]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@wrap('drjit', 'tf')\n",
    "def test_fn(x, y, z):\n",
    "    return x*2, y, z\n",
    "\n",
    "x = dr.arange(dr.llvm.ad.Float, 3)\n",
    "dr.enable_grad(x)\n",
    "\n",
    "a, b, c = test_fn(x, 4, 5.0)\n",
    "#assert dr.all(a == x*2) and dr.all(b == 4) and dr.all(c == 5)\n",
    "\n",
    "a.grad = [10, 20, 30]\n",
    "dr.backward_to(x)\n",
    "\n",
    "#assert dr.all(x.grad == [20, 40, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 4, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Forward-mode AD\n",
    "@wrap('drjit', 'torch')\n",
    "def fn(x):\n",
    "    return x**2\n",
    "\n",
    "x = dr.arange(dr.llvm.ad.Float, 3)\n",
    "dr.enable_grad(x)\n",
    "y = fn(x)\n",
    "y.grad = [1, 2, 1]\n",
    "dr.backward_to(x)\n",
    "x.grad\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tf.Tensor([1. 2. 3. 4.], shape=(4,), dtype=float32)\n",
      "y: tf.Tensor([ 1.  4.  9. 16.], shape=(4,), dtype=float32)\n",
      "Gradient: tf.Tensor([2. 4. 6. 8.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test for a single tensor input\n",
    "\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(input):\n",
    "    return dr.power(input, 2)\n",
    "\n",
    "x = tf.constant([1,2,3,4], tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = dr_func(x)\n",
    "grad = tape.gradient(y, x)\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "print(\"Gradient:\", grad)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: tf.Tensor([ 3. 14. 39. 84.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([2. 4. 6. 8.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([ 3. 12. 27. 48.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test with a list of tensors\n",
    "\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(inputs):\n",
    "    result = 0\n",
    "    for i, input in enumerate(inputs):\n",
    "        result += dr.power(input, i+1)\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x3 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "vars = [x1, x2, x3]\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(vars)\n",
    "    result = dr_func(vars)\n",
    "grad = tape.gradient(result, vars)\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: tf.Tensor([  4.  30. 120. 340.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "[<tf.Tensor: shape=(4,), dtype=float32, numpy=array([2., 4., 6., 8.], dtype=float32)>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 3., 12., 27., 48.], dtype=float32)>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([  4.,  32., 108., 256.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# Test with a nested list of tensors\n",
    "# Test with a list of tensors\n",
    "\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(inputs):\n",
    "    inputs = sum(inputs, [])\n",
    "    result = 0\n",
    "    for i, input in enumerate(inputs):\n",
    "        result += dr.power(input, i+1)\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x3 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x4 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "vars = [[x1, x2], [x3, x4]]\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(vars)\n",
    "    result = dr_func(vars)\n",
    "grad = tape.gradient(result, [x1, [x2, x3, x4]])\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: tf.Tensor([ 2. 10. 30. 68.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([ 3. 12. 27. 48.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test with multiple arguments\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(x1, x2):\n",
    "    return dr.power(x1, 1) + dr.power(x2, 3)\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2])\n",
    "    result = dr_func(x1, x2)\n",
    "grad = tape.gradient(result, [x1, x2])\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>, <tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 4.,  6.,  8., 10.], dtype=float32)>, None]\n"
     ]
    }
   ],
   "source": [
    "# Test with keyword argument\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(*args, **kwargs):\n",
    "    result = 0\n",
    "    for i, x in enumerate(args[0]):\n",
    "        result += dr.power(x, i+1)\n",
    "\n",
    "    for i, x in enumerate(kwargs.values()):\n",
    "        result += 4*x\n",
    "\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([2, 3, 4, 5], dtype=tf.float32)\n",
    "x3 = tf.constant([3, 4, 4, 5], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2, x3])\n",
    "    result = dr_func([x1, x2], x3=x3)\n",
    "grad = tape.gradient(result, [x1, x2, x3])\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([320. 332. 336. 348.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([4. 4. 4. 4.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Test with dict argument\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(*args, **kwargs):\n",
    "    result = 0\n",
    "    for i, x in enumerate(args[0]):\n",
    "        result += dr.power(x, i+1)\n",
    "\n",
    "    for i, x in enumerate(args[1].values()):\n",
    "        result += 4*(i+1)*x\n",
    "\n",
    "    return result\n",
    "\n",
    "def tf_func(*args, **kwargs):\n",
    "    result = 0\n",
    "    for i, x in enumerate(args[0]):\n",
    "        result += tf.pow(x, i+1)\n",
    "\n",
    "    for i, x in enumerate(args[1].values()):\n",
    "        result += 4*(i+1)*x\n",
    "\n",
    "    return result\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([2, 3, 4, 5], dtype=tf.float32)\n",
    "x3 = tf.constant([3, 4, 4, 5], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2, x3])\n",
    "    result = dr_func(x1, {'x2' : x2, 'x3': x3})\n",
    "grad = tape.gradient(result, [x2])\n",
    "print(result)\n",
    "for g in grad:\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.autodiff import ForwardAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int32\n",
      "Result: tf.Tensor([2. 4. 6. 8.], shape=(4,), dtype=float32)\n",
      "Gradient:\n",
      "tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test with a non differentiable input\n",
    "@wrap('tf', 'drjit')\n",
    "def dr_func(x1, x2):\n",
    "    return dr.power(x1, 1) + dr.power(x2, 1)\n",
    "\n",
    "def tf_func(x1, x2):\n",
    "    return tf.pow(x1, 1) + tf.cast(tf.pow(x2, 1), x1.dtype)\n",
    "\n",
    "x1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "x2 = tf.constant([1, 2, 3, 4], dtype=tf.int32)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([x1, x2])\n",
    "    result = dr_func(x1, x2)\n",
    "grad = tape.gradient(result, [x1, x2])\n",
    "print(\"Result:\", result)\n",
    "print(\"Gradient:\")\n",
    "for g in grad:\n",
    "    print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 2., 3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.constant([1,2,3,4], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drjit as dr\n",
    "from drjit.cuda.ad import Float\n",
    "from drjit.cuda.ad import Int32\n",
    "\n",
    "t = Int32\n",
    "is_diff = False\n",
    "\n",
    "@wrap('drjit', 'torch')\n",
    "def test_fn(x):\n",
    "    return x * 2\n",
    "\n",
    "x = dr.arange(t, 3)\n",
    "dr.enable_grad(x)\n",
    "y = test_fn(x)\n",
    "assert dr.all(y == [0, 2, 4])\n",
    "\n",
    "\n",
    "if is_diff:\n",
    "    y.grad = [10, 20, 30]\n",
    "    dr.backward_to(x)\n",
    "    assert dr.all(x.grad == [20, 40, 60])\n",
    "else:\n",
    "    assert not dr.grad_enabled(y)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interop import from_drjit, to_drjit\n",
    "\n",
    "t = dr.llvm.ad.Float\n",
    "x = dr.arange(t, 3)\n",
    "z, _ = from_drjit(x, 'tf', True)\n",
    "y = z*2\n",
    "z_ = to_drjit(y, 'tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import drjit as dr\n",
    "\n",
    "\n",
    "@wrap('drjit', 'tf')\n",
    "def test_fn(x):\n",
    "    y = x*2\n",
    "    print(y.device)\n",
    "    return y\n",
    "\n",
    "t = dr.cuda.ad.Float\n",
    "x = dr.arange(t, 3)\n",
    "y = test_fn(x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
